{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 值迭代\n",
    "## 1.游戏环境设置"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 游戏环境设置：\n",
    "# 4x12，（11，11）是终点，最下面一行除了（3，0）以外全是不可走的地方\n",
    "#获取一个格子的状态\n",
    "def get_state(row, col):\n",
    "    if row != 3:\n",
    "        return 'ground'\n",
    "\n",
    "    if row == 3 and col == 0:\n",
    "        return 'ground'\n",
    "\n",
    "    if row == 3 and col == 11:\n",
    "        return 'terminal'\n",
    "\n",
    "    return 'trap'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 设定agent在每一个格子里的动作\n",
    "def move(row, col, action):\n",
    "    # 如果当前已经在陷阱或者终点，则不能执行任何动作，反馈都是0\n",
    "    if get_state(row, col) in ['trap', 'terminal']:\n",
    "        return row, col, 0\n",
    "\n",
    "    # 执行动作\n",
    "    if action == 0:   # ↑\n",
    "        row -= 1\n",
    "    elif action == 1: # ↓\n",
    "        row += 1\n",
    "    elif action == 2: # ←\n",
    "        col -= 1\n",
    "    elif action == 3: # →\n",
    "        col += 1\n",
    "\n",
    "    # 初始化reward\n",
    "    reward = -1  # 这样强迫了机器尽快结束游戏,因为每走一步都要扣一分\n",
    "\n",
    "    # 不允许走到地图外面去，撞墙扣5分\n",
    "    if row < 0 or row > 3 or col < 0 or col > 11:\n",
    "        reward = -5\n",
    "        row = max(0, min(row, 3))\n",
    "        col = max(0, min(col, 11))\n",
    "\n",
    "    # 是陷阱的话，奖励是-100\n",
    "    # 结束最好是以走到终点的形式,避免被扣100分\n",
    "    state = get_state(row, col)\n",
    "    if state == 'trap':\n",
    "        reward = -100\n",
    "    elif state == 'terminal':\n",
    "        reward = 100\n",
    "\n",
    "    return row, col, reward"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.算法设置"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 计算在一个状态下执行动作的分数\n",
    "def get_qsa(values, row, col, action):\n",
    "    # 在当前状态下执行动作,得到下一个状态和reward\n",
    "    next_row, next_col, reward = move(row, col, action)\n",
    "\n",
    "    # 计算下一个状态的分数,取values当中记录的分数即可,0.9是折扣因子γ\n",
    "    value = values[next_row, next_col] * 0.9\n",
    "\n",
    "    # 如果下个状态是陷阱,则下一个状态的分数是0\n",
    "    if get_state(next_row, next_col) in ['trap','terminal']:\n",
    "        value = 0\n",
    "\n",
    "    # 动作的分数本身就是reward,加上下一个状态的分数\n",
    "    return value + reward"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 值迭代算法"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def valueIteration(values, pi, threshold=0.000001):\n",
    "    while True:\n",
    "        # 初始化一个新的values，重新评估所有格子的分数\n",
    "        new_values = np.copy(values)\n",
    "\n",
    "        # 重新初始化每个格子下采用动作的概率，重新评估\n",
    "        new_pi = np.copy(pi)\n",
    "\n",
    "        # 遍历所有格子\n",
    "        for row in range(4):\n",
    "            for col in range(12):\n",
    "                # 计算当前格子4个动作分别的分数\n",
    "                action_values = np.zeros(4)\n",
    "                maxActionIdx = 0\n",
    "                # 遍历所有动作\n",
    "                for action in range(4):\n",
    "                    action_values[action] = get_qsa(values, row, col, action)\n",
    "                    # 获取q值最大的动作作为下一步的动作\n",
    "                    if action_values[action] > action_values[maxActionIdx]:\n",
    "                        maxActionIdx = action\n",
    "                # 策略更新\n",
    "                # 将动作值最大的动作作为下一步\n",
    "                # 让该动作的概率为1，其他动作的概率为0\n",
    "                new_pi[row, col, :] = 0  # 将所有动作的概率重置为0\n",
    "                new_pi[row, col, maxActionIdx] = 1  # 将最优动作的概率设置为1\n",
    "\n",
    "                # 值更新\n",
    "                # 求每一个格子的分数，等于该格子下所有动作的最大分数\n",
    "                new_values[row, col] = action_values[maxActionIdx]\n",
    "\n",
    "        # 检查是否收敛 ||v_k - v_k-1 || < threshold?\n",
    "        if np.allclose(new_values, values, atol=threshold):\n",
    "            break\n",
    "        # 更新价值函数和策略\n",
    "        values = new_values\n",
    "        pi = new_pi\n",
    "\n",
    "    return values, pi\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.游戏初始化与训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 17.96052411,  21.06724901,  24.51916557,  28.35462841,\n         32.61625379,  37.3513931 ,  42.612659  ,  48.45851   ,\n         54.9539    ,  62.171     ,  70.19      ,  79.1       ],\n       [ 21.06724901,  24.51916557,  28.35462841,  32.61625379,\n         37.3513931 ,  42.612659  ,  48.45851   ,  54.9539    ,\n         62.171     ,  70.19      ,  79.1       ,  89.        ],\n       [ 24.51916557,  28.35462841,  32.61625379,  37.3513931 ,\n         42.612659  ,  48.45851   ,  54.9539    ,  62.171     ,\n         70.19      ,  79.1       ,  89.        , 100.        ],\n       [ 21.06724901,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ,\n          0.        ,   0.        ,   0.        ,   0.        ]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#初始化每个格子的价值\n",
    "values = np.zeros([4, 12])\n",
    "\n",
    "#初始化每个格子下采用动作的概率\n",
    "pi = np.ones([4, 12, 4]) * 0.25\n",
    "#循环迭代策略评估和策略提升，寻找最优解\n",
    "\n",
    "values, pi = valueIteration(values,pi)\n",
    "values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.训练结果可视化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "□□□□□□□□□□□□\n",
      "□↑□□□□□□□□□□\n",
      "□□□□□□□□□□□□\n",
      "□○○○○○○○○○○❤\n"
     ]
    }
   ],
   "source": [
    "#打印游戏，方便测试\n",
    "def show(row, col, action):\n",
    "    graph = [\n",
    "        '□', '□', '□', '□', '□', '□', '□', '□', '□', '□', '□', '□', '□', '□',\n",
    "        '□', '□', '□', '□', '□', '□', '□', '□', '□', '□', '□', '□', '□', '□',\n",
    "        '□', '□', '□', '□', '□', '□', '□', '□', '□', '○', '○', '○', '○', '○',\n",
    "        '○', '○', '○', '○', '○', '❤'\n",
    "    ]\n",
    "\n",
    "    action = {0: '↑', 1: '↓', 2: '←', 3: '→'}[action]\n",
    "\n",
    "    graph[row * 12 + col] = action\n",
    "\n",
    "    graph = ''.join(graph)\n",
    "\n",
    "    for i in range(0, 4 * 12, 12):\n",
    "        print(graph[i:i + 12])\n",
    "\n",
    "\n",
    "show(1, 1, 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import time\n",
    "\n",
    "\n",
    "def test():\n",
    "    #起点在0,0\n",
    "    row = 0\n",
    "    col = 0\n",
    "\n",
    "    #最多玩N步\n",
    "    for _ in range(200):\n",
    "\n",
    "        #选择一个动作\n",
    "        action = np.random.choice(np.arange(4), size=1, p=pi[row, col])[0]\n",
    "\n",
    "        #打印这个动作\n",
    "        display.clear_output(wait=True)\n",
    "        time.sleep(0.3)\n",
    "        show(row, col, action)\n",
    "\n",
    "        #执行动作\n",
    "        row, col, reward = move(row, col, action)\n",
    "\n",
    "        #获取当前状态，如果状态是终点或者掉陷阱则终止\n",
    "        if get_state(row, col) in ['trap', 'terminal']:\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[8], line 18\u001B[0m, in \u001B[0;36mtest\u001B[1;34m()\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m#打印这个动作\u001B[39;00m\n\u001B[0;32m     17\u001B[0m display\u001B[38;5;241m.\u001B[39mclear_output(wait\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 18\u001B[0m \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.3\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m show(row, col, action)\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m#执行动作\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "test()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
