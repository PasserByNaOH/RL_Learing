{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 蒙特卡洛 Exploring Starts算法\n",
    "## 1.游戏环境设置"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# 构造一个网格环境(3x3)\n",
    "def get_state(row, col):\n",
    "    if row == 0 and col == 1:\n",
    "        return 'trap'\n",
    "    if row == 2 and col == 0:\n",
    "        return 'trap'\n",
    "    if row == 2 and col == 2:\n",
    "        return 'terminal'\n",
    "    return 'ground'\n",
    "\n",
    "\n",
    "# 设定agent在每一个格子里的动作\n",
    "def move(row, col, action):\n",
    "    # 如果当前已经在陷阱或者终点，则不能执行任何动作，反馈都是0\n",
    "    if get_state(row, col) in ['trap', 'terminal']:\n",
    "        return row, col, 0\n",
    "\n",
    "    # 执行动作\n",
    "    if action == 0:  # ↑\n",
    "        row -= 1\n",
    "    elif action == 1:  # ↓\n",
    "        row += 1\n",
    "    elif action == 2:  # ←\n",
    "        col -= 1\n",
    "    elif action == 3:  # →\n",
    "        col += 1\n",
    "\n",
    "    # 初始化reward\n",
    "    reward = -1  # 这样强迫了机器尽快结束游戏,因为每走一步都要扣一分\n",
    "\n",
    "    # 不允许走到地图外面去，撞墙扣5分\n",
    "    if row < 0 or row > 2 or col < 0 or col > 2:\n",
    "        reward = -5\n",
    "        row = max(0, min(row, 2))\n",
    "        col = max(0, min(col, 2))\n",
    "\n",
    "    # 是陷阱的话，奖励是-100\n",
    "    # 结束最好是以走到终点的形式,避免被扣100分\n",
    "    state = get_state(row, col)\n",
    "    if state == 'trap':\n",
    "        reward = -100\n",
    "    elif state == 'terminal':\n",
    "        reward = 100\n",
    "\n",
    "    return row, col, reward"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.游戏环境初始化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 3., 3.],\n       [3., 3., 1.],\n       [3., 2., 1.]])"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "# 初始化每个格子的价值\n",
    "values = np.zeros([3, 3])\n",
    "# 初始化策略\n",
    "actions = [0, 1, 2, 3]\n",
    "pi = np.zeros([3, 3])\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        pi[row, col] = random.choice(actions)\n",
    "pi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.算法设置"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# 生成一个回合\n",
    "def generate_episode(start_row, start_col, policy):\n",
    "    episode = []\n",
    "    row, col = start_row, start_col\n",
    "    # 设置一个episode长度为30, 设置较长的episode保证尽量能够访问所有的状态\n",
    "    for _ in range(30):\n",
    "        # 检查是否到达终止状态\n",
    "        if get_state(row, col) in ['trap', 'terminal']:\n",
    "            break\n",
    "        action = policy[row, col]\n",
    "        next_row, next_col, reward = move(row, col, action)\n",
    "        episode.append(((row, col), action, reward))\n",
    "        row, col = next_row, next_col\n",
    "    return episode"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# MC Exploring Starts算法\n",
    "def MonteCarlo_ExploringStarts(values, policy,actions, num_iterations, gamma=0.9):\n",
    "    returns = {}  # 存储每个状态-动作对的回报列表\n",
    "    for _ in range(num_iterations):\n",
    "\n",
    "        # MC Exploring Starts算法的初始状态是随机的\n",
    "        # 随机选择一个状态-动作对作为起点\n",
    "        start_row = random.randint(0, 2)\n",
    "        start_col = random.randint(0, 2)\n",
    "        episode = generate_episode(start_row, start_col, policy)  # 在第一个随机动作之后使用提供的策略\n",
    "\n",
    "\n",
    "        # 策略评估\n",
    "        G = 0\n",
    "        # 采用首次访问策略\n",
    "        visited = set()  # 用于记录已访问的状态-动作对\n",
    "        # 倒序计算，节省时间\n",
    "        for step in reversed(range(len(episode))):\n",
    "            state, act, reward = episode[step]\n",
    "            G = gamma * G + reward\n",
    "            # 仅当状态-动作对第一次访问时计算回报\n",
    "            if (state, act) not in visited:\n",
    "                visited.add((state, act))\n",
    "                if (state,act) not in returns:\n",
    "                    returns[(state, act)] = []\n",
    "                returns[(state, act)].append(G)\n",
    "                # 更新状态值（即从当前状态-动作对开始的平均值）\n",
    "                values[state[0], state[1]] = np.mean(returns[(state, act)])\n",
    "\n",
    "        # 策略提升\n",
    "        for row in range(3):\n",
    "            for col in range(3):\n",
    "                action_values = [np.mean(returns.get(((row, col), a), [0])) for a in actions]\n",
    "                best_action_index = np.argmax(action_values)\n",
    "                best_action = actions[best_action_index]\n",
    "                policy[row, col] = best_action\n",
    "    return values, policy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 0., 1.],\n       [3., 3., 1.],\n       [0., 0., 0.]])"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 有时候训练无法得到结果\n",
    "values, pi = MonteCarlo_ExploringStarts(values, pi, actions, 100)\n",
    "pi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.结果展示"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# 打印游戏，方便测试\n",
    "def show(row, col, action):\n",
    "    graph = [\n",
    "        '□', '□', '○', '□', '□', '□', '○', '□', '❤'\n",
    "    ]\n",
    "\n",
    "    action = {0: '↑', 1: '↓', 2: '←', 3: '→'}[action]\n",
    "\n",
    "    graph[row * 3 + col] = action\n",
    "\n",
    "    graph = ''.join(graph)\n",
    "\n",
    "    for i in range(0, 3 * 3, 3):\n",
    "        print(graph[i:i + 3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import time\n",
    "\n",
    "\n",
    "def test():\n",
    "    #起点在0,0\n",
    "    row = 0\n",
    "    col = 0\n",
    "\n",
    "    #最多玩N步\n",
    "    for _ in range(200):\n",
    "\n",
    "        #选择一个动作\n",
    "        action = pi[row, col]\n",
    "\n",
    "        #打印这个动作\n",
    "        display.clear_output(wait=True)\n",
    "        time.sleep(0.5)\n",
    "        show(row, col, action)\n",
    "\n",
    "        #执行动作\n",
    "        row, col, reward = move(row, col, action)\n",
    "\n",
    "        #获取当前状态，如果状态是终点或者掉陷阱则终止\n",
    "        if get_state(row, col) in ['trap', 'terminal']:\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "□□○\n",
      "□□□\n",
      "○→❤\n"
     ]
    }
   ],
   "source": [
    "test()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
