{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 蒙特卡洛基础方法\n",
    "## 1.环境设置"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# 构造一个网格环境(3x3)\n",
    "def get_state(row, col):\n",
    "    if row == 0 and col == 1:\n",
    "        return 'trap'\n",
    "    if row == 2 and col == 0:\n",
    "        return 'trap'\n",
    "    if row == 2 and col == 2:\n",
    "        return 'terminal'\n",
    "    return 'ground'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# 设定agent在每一个格子里的动作\n",
    "def move(row, col, action):\n",
    "    # 如果当前已经在陷阱或者终点，则不能执行任何动作，反馈都是0\n",
    "    if get_state(row, col) in ['trap', 'terminal']:\n",
    "        return row, col, 0\n",
    "\n",
    "    # 执行动作\n",
    "    if action == 0:   # ↑\n",
    "        row -= 1\n",
    "    elif action == 1: # ↓\n",
    "        row += 1\n",
    "    elif action == 2: # ←\n",
    "        col -= 1\n",
    "    elif action == 3: # →\n",
    "        col += 1\n",
    "\n",
    "    # 初始化reward\n",
    "    reward = -1  # 这样强迫了机器尽快结束游戏,因为每走一步都要扣一分\n",
    "\n",
    "    # 不允许走到地图外面去，撞墙扣5分\n",
    "    if row < 0 or row > 2 or col < 0 or col > 2:\n",
    "        reward = -5\n",
    "        row = max(0, min(row, 2))\n",
    "        col = max(0, min(col, 2))\n",
    "\n",
    "    # 是陷阱的话，奖励是-100\n",
    "    # 结束最好是以走到终点的形式,避免被扣100分\n",
    "    state = get_state(row, col)\n",
    "    if state == 'trap':\n",
    "        reward = -100\n",
    "    elif state == 'terminal':\n",
    "        reward = 100\n",
    "\n",
    "    return row, col, reward"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.游戏环境初始化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 0., 1.],\n       [2., 2., 3.],\n       [3., 2., 3.]])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "# 初始化每个格子的价值\n",
    "values = np.zeros([3, 3])\n",
    "# 初始化策略\n",
    "actions = [0, 1, 2, 3]\n",
    "pi = np.zeros([3, 3])\n",
    "for row in range(3):\n",
    "    for col in range(3):\n",
    "        pi[row, col] = random.choice(actions)\n",
    "pi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.算法设置"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# 生成一个回合\n",
    "def generate_episode(start_row, start_col, policy):\n",
    "    episode = []\n",
    "    row, col = start_row, start_col\n",
    "    # 设置一个episode长度为30（以免过长）\n",
    "    for _ in range(30):\n",
    "        # 检查是否到达终止状态\n",
    "        if get_state(row, col) in ['trap', 'terminal']:\n",
    "            break\n",
    "        action = policy[row, col]\n",
    "        next_row, next_col, reward = move(row, col, action)\n",
    "        episode.append(((row, col), action, reward))\n",
    "        row, col = next_row, next_col\n",
    "    return episode"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# MC算法\n",
    "def MonteCarlo_Basic(values, policy,actions, num_iterations, gamma=0.9):\n",
    "    returns = {}  # 存储每个状态-动作对的回报列表\n",
    "    for _ in range(num_iterations):\n",
    "        # 对于每一个状态的每一个动作\n",
    "        for row in range(3):\n",
    "            for col in range(3):\n",
    "                for action in range(4):\n",
    "                    # 从每个状态-动作对开始生成一个回合\n",
    "                    episode = generate_episode(row, col, policy)\n",
    "\n",
    "                    # 策略评估\n",
    "                    G = 0\n",
    "                    for step in range(len(episode)):\n",
    "                        state, act, reward = episode[step]\n",
    "                        G = gamma * G + reward\n",
    "                        # 每次访问(s,a)都计算回报\n",
    "                        if state == (row, col) and act == action:\n",
    "                            if (state, action) not in returns:\n",
    "                                returns[(state, action)] = []\n",
    "                            returns[(state, action)].append(G)\n",
    "                            # 更新状态值（即从当前状态-动作对开始的平均值）\n",
    "                            values[state[0], state[1]] = np.mean(returns[(state, action)])\n",
    "\n",
    "                # 策略提升\n",
    "                action_values = [np.mean(returns.get(((row, col), a), [0])) for a in actions]\n",
    "                best_action_index = np.argmax(action_values)\n",
    "                best_action = actions[best_action_index]\n",
    "                policy[row, col] = best_action\n",
    "    return values, policy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 0., 1.],\n       [3., 1., 1.],\n       [0., 3., 0.]])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, pi = MonteCarlo_Basic(values, pi, actions, 10)\n",
    "pi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.结果展示"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 打印游戏，方便测试\n",
    "def show(row, col, action):\n",
    "    graph = [\n",
    "        '□', '□', '○', '□', '□', '□', '○', '□', '❤'\n",
    "    ]\n",
    "\n",
    "    action = {0: '↑', 1: '↓', 2: '←', 3: '→'}[action]\n",
    "\n",
    "    graph[row * 3 + col] = action\n",
    "\n",
    "    graph = ''.join(graph)\n",
    "\n",
    "    for i in range(0, 3 * 3, 3):\n",
    "        print(graph[i:i + 3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import time\n",
    "\n",
    "\n",
    "def test():\n",
    "    #起点在0,0\n",
    "    row = 0\n",
    "    col = 0\n",
    "\n",
    "    #最多玩N步\n",
    "    for _ in range(200):\n",
    "\n",
    "        #选择一个动作\n",
    "        action = pi[row, col]\n",
    "\n",
    "        #打印这个动作\n",
    "        display.clear_output(wait=True)\n",
    "        time.sleep(0.5)\n",
    "        show(row, col, action)\n",
    "\n",
    "        #执行动作\n",
    "        row, col, reward = move(row, col, action)\n",
    "\n",
    "        #获取当前状态，如果状态是终点或者掉陷阱则终止\n",
    "        if get_state(row, col) in ['trap', 'terminal']:\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "□□○\n",
      "□□↓\n",
      "○□❤\n"
     ]
    }
   ],
   "source": [
    "test()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
